{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cbdfaad8",
      "metadata": {
        "id": "cbdfaad8"
      },
      "source": [
        "---\n",
        "title: Building an AI agent from scratch in Python\n",
        "subtitle: \"How to implement a single AI agent with an LLM API and no frameworks.\"\n",
        "description: \"Learn how to build an AI agent from scratch in Python using LLM API calls, function calling, and conversation memory.\"\n",
        "date: 2025-09-30\n",
        "toc: true\n",
        "---\n",
        "\n",
        "What's the best way to get started building AI agent systems? There are countless frameworks for building AI agents available, such as [CrewAI](https://www.crewai.com/), [LangGraph](https://www.langchain.com/langgraph), and the [OpenAI Agents SDK](https://openai.github.io/openai-agents-python/), and it can be overwhelming to choose one.\n",
        "On the other hand, [Anthropic recommended starting with using direct LLM APIs calls](https://www.anthropic.com/engineering/building-effective-agents) to understand the fundamentals before relying on framework abstractions.\n",
        "\n",
        "This tutorial takes this approach by exploring how to implement an AI agent from scratch in Python using an LLM API directly to gain a better understanding of what's happening under the hood.\n",
        "This tutorial focuses on implementing a singleagent before advancing to more complex topics, such as agentic workflows or multi-agent systems."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50f8b112",
      "metadata": {
        "id": "50f8b112"
      },
      "source": [
        "## Implementing an AI Agent from scratch\n",
        "\n",
        "This section implements an `Agent()` class by incorporating each of the following core components of an AI agent step-by-step:\n",
        "\n",
        "1. **LLM and instructions:** The LLM powering the agent's reasoning and decision-making capabilities with explicit guidelines defining how the agent should behave.\n",
        "2. **Memory:** Conversation history (short-term memory) the agent uses to understand the current interaction.\n",
        "3. **Tools:** External functions or APIs the agent can call.\n",
        "\n",
        "And finally, we will put everything together in a loop."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c213722",
      "metadata": {
        "id": "1c213722"
      },
      "source": [
        "### Component 1: LLM and Instructions\n",
        "\n",
        "At the core of every AI agent, you have a Large Language Model (LLM) with tool use capabilities, such as Anthropic's Claude 4 Sonnet, OpenAI's GPT-4o, or Google's Gemini 2.5 Pro.\n",
        "\n",
        "This tutorial uses Claude 4 Sonnet through the Anthropic API but you can easily adjust the code to any other LLM API of your choice.\n",
        "\n",
        "To use the Anthropic API, you will need an `ANTHROPIC_API_KEY`, which you can obtain by creating an Anthropic account and navigating to the \"API Keys\" tab in your dashboard. Once you have your API key, you need to store it in the environment variables, an .env file, or the Google Colab secrets, depending on the environment you're using.\n",
        "\n",
        "Let's install and import the required libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "320169a6",
      "metadata": {
        "id": "320169a6"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install -U anthropic python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "79e682e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79e682e5",
        "outputId": "013d9659-24da-4836-942e-13d2e52cc7f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.69.0\n"
          ]
        }
      ],
      "source": [
        "import anthropic\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from google.colab import userdata\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "print(anthropic.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad122bf6",
      "metadata": {
        "id": "ad122bf6"
      },
      "source": [
        "Now, we will implement a simple `Agent` class with the following components:\n",
        "\n",
        "- Initialization: Sets up the LLM client and configures the model with a system prompt that contains instruction for the agent on how to act. (You could also turn this into a parameter you can pass to the agent but we will use a fixed one for simplicity.)\n",
        "- `chat` method: Processes user messages by sending them to the LLM API and returning the response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b3264d0",
      "metadata": {
        "id": "4b3264d0"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Agent:\n",
        "    \"\"\"A simple AI agent that can answer questions\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.client = anthropic.Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
        "        self.model = \"claude-sonnet-4-20250514\"\n",
        "        self.system_message = \"You are a helpful assistant that breaks down problems into steps and solves them systematically.\"\n",
        "\n",
        "    def chat(self, message):\n",
        "        \"\"\"Process a user message and return a response\"\"\"\n",
        "\n",
        "        response = self.client.messages.create(\n",
        "            model=self.model,\n",
        "            max_tokens=1024,\n",
        "            system=self.system_message,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": message}\n",
        "                ],\n",
        "            temperature=0.1,\n",
        "        )\n",
        "\n",
        "        return response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06c9a0f7",
      "metadata": {
        "id": "06c9a0f7"
      },
      "source": [
        "The agent now has simple query-response capabilities. Let's test it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "36fd0d14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36fd0d14",
        "outputId": "ca283663-d6b9-4434-aa25-903c3970cdcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I don't have any apples - as an AI, I don't have a physical form, so I can't possess physical objects like apples. Only you have apples in this scenario (4 of them). \n",
            "\n",
            "Is there something you'd like to do with this information, like a math problem involving your apples?\n"
          ]
        }
      ],
      "source": [
        "agent = Agent()\n",
        "\n",
        "response = agent.chat(\"I have 4 apples. How many do you have?\")\n",
        "print(response.content[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a58330fd",
      "metadata": {
        "id": "a58330fd"
      },
      "source": [
        "Great. Let's follow up with a second message."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "16526fa9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16526fa9",
        "outputId": "51a24aab-3e45-4839-804b-c8895990b8b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I don't have enough information to answer how many apples are left. To solve this, I would need to know:\n",
            "\n",
            "**What I need:**\n",
            "- How many apples you started with\n",
            "\n",
            "**The calculation would be:**\n",
            "Starting number of apples - 1 apple eaten = Apples remaining\n",
            "\n",
            "Could you tell me how many apples you had before eating one?\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\"I ate 1 apple. How many are left?\")\n",
        "print(response.content[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1924726b",
      "metadata": {
        "id": "1924726b"
      },
      "source": [
        "As you can see, the agent lacks the information from the first message. That's why we need to give the agent access to the conversation history."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21d08c0d",
      "metadata": {
        "id": "21d08c0d"
      },
      "source": [
        "### Component 2: (Conversation) Memory\n",
        "\n",
        "Memory in agents can take many different forms, such as short-term and long-term memory, and memory management can become a complex topic.\n",
        "For the sake of this tutorial, let's keep it simple and start with a basic short-term memory implementation.\n",
        "\n",
        "Short-term memory gives the agent access to the conversation history to understand the current interaction.\n",
        "In its simplest form, the short-term memory is just a list of past `messages` between the `user` and the `assistant`. (Note, that the longer the conversation history becomes, you will run into context window limitations and will need to implement a more sophisticated solution.)\n",
        "\n",
        "We implement short-term memory by adding a `messages` property where we store both:\n",
        "\n",
        "- the user inputs with `{\"role\": \"user\", \"content\": message}`\n",
        "- the response with `{\"role\": \"assistant\", \"content\": response.content}`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1c55994",
      "metadata": {
        "id": "c1c55994"
      },
      "outputs": [],
      "source": [
        "class Agent:\n",
        "    \"\"\"A simple AI agent that can answer questions in a multi-turn conversation\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.client = anthropic.Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
        "        self.model = \"claude-sonnet-4-20250514\"\n",
        "        self.system_message = \"You are a helpful assistant that breaks down problems into steps and solves them systematically.\"\n",
        "        self.messages = []\n",
        "\n",
        "    def chat(self, message):\n",
        "        \"\"\"Process a user message and return a response\"\"\"\n",
        "\n",
        "        # Store user input in short-term memory\n",
        "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "        response = self.client.messages.create(\n",
        "            model=self.model,\n",
        "            max_tokens=1024,\n",
        "            system=self.system_message,\n",
        "            messages=self.messages,\n",
        "            temperature=0.1,\n",
        "        )\n",
        "\n",
        "        # Store assistant's response in short-term memory\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": response.content})\n",
        "\n",
        "        return response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81b388e8",
      "metadata": {
        "id": "81b388e8"
      },
      "source": [
        "Now, let's test the agent again with the previous example conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9120bbc9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9120bbc9",
        "outputId": "2deab10e-f98f-4963-f587-864a886b563a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I don't have any apples - as an AI, I don't have a physical form and can't possess physical objects like apples. You have 4 apples, and I have 0 apples.\n",
            "\n",
            "Is there something you'd like to do with your 4 apples, like a math problem or recipe suggestion?\n",
            "Let me solve this step by step:\n",
            "\n",
            "**Step 1:** Identify the starting amount\n",
            "- You started with 4 apples\n",
            "\n",
            "**Step 2:** Identify what was consumed\n",
            "- You ate 1 apple\n",
            "\n",
            "**Step 3:** Calculate the remaining amount\n",
            "- Apples left = Starting amount - Apples eaten\n",
            "- Apples left = 4 - 1 = 3\n",
            "\n",
            "**Answer:** You have 3 apples left.\n"
          ]
        }
      ],
      "source": [
        "agent = Agent()\n",
        "\n",
        "response = agent.chat(\"I have 4 apples. How many do you have?\")\n",
        "print(response.content[0].text)\n",
        "\n",
        "response = agent.chat(\"I ate 1 apple. How many are left?\")\n",
        "print(response.content[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4c5d582",
      "metadata": {
        "id": "f4c5d582"
      },
      "source": [
        "As you can see, the agent is now able to hold a conversation and to reference previous information.\n",
        "\n",
        "But what happens, if you task the agent with a little more complex math problem?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "673a59df",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "673a59df",
        "outputId": "a1e56aa1-8edb-4f5c-cec7-d472dc292764"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I'll solve this step by step using the standard multiplication algorithm.\n",
            "\n",
            "157.09 × 493.89\n",
            "\n",
            "First, let me multiply 157.09 by each digit of 493.89:\n",
            "\n",
            "**Step 1:** 157.09 × 9 (ones place)\n",
            "157.09 × 9 = 1,413.81\n",
            "\n",
            "**Step 2:** 157.09 × 80 (tens place)\n",
            "157.09 × 8 = 1,256.72\n",
            "1,256.72 × 10 = 12,567.2\n",
            "\n",
            "**Step 3:** 157.09 × 300 (hundreds place)\n",
            "157.09 × 3 = 471.27\n",
            "471.27 × 100 = 47,127\n",
            "\n",
            "**Step 4:** 157.09 × 90,000 (ten-thousands place)\n",
            "157.09 × 9 = 1,413.81\n",
            "1,413.81 × 10,000 = 14,138,100\n",
            "\n",
            "**Step 5:** 157.09 × 400,000 (hundred-thousands place)\n",
            "157.09 × 4 = 628.36\n",
            "628.36 × 100,000 = 62,836,000\n",
            "\n",
            "**Step 6:** Add all partial products:\n",
            "```\n",
            "    1,413.81\n",
            "   12,567.2\n",
            "   47,127\n",
            "14,138,100\n",
            "62,836,000\n",
            "-----------\n",
            "77,035,208.01\n",
            "```\n",
            "\n",
            "Therefore, **157.09 × 493.89 = 77,035.2081**\n"
          ]
        }
      ],
      "source": [
        "agent = Agent()\n",
        "\n",
        "response = agent.chat(\"What is 157.09 * 493.89?\")\n",
        "\n",
        "print(response.content[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EoWCOgi1ec_U",
      "metadata": {
        "id": "EoWCOgi1ec_U"
      },
      "source": [
        "The agent's answer sounds perfectly believable but if you validate it, you can actually see that even powerful LLMs like Claude 4 Sonnet can still make arithmetic errors without tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "181d79_peYBa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "181d79_peYBa",
        "outputId": "417b038f-6699-48c1-aa0a-4b8170a18e88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "77585.1801"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "157.09 * 493.89"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da0f95e0",
      "metadata": {
        "id": "da0f95e0"
      },
      "source": [
        "### Component 3: Tool Use\n",
        "\n",
        "To extend the agent's capabilities, you can provide it with tools that can range from simple functions to using external APIs. For this tutorial, we will implement a simple `CalculatorTool` class, that can handle math problems.\n",
        "\n",
        "The exact implemention of tool use is different across providers, but at the core always requires two key components:\n",
        "\n",
        "- **Function implementation:** This is the actual function that executes the tool's logic, such as performing a calculation, or making an API call.\n",
        "- **Tool schema:** A structured description of the tool. The tool description is important because it tells the LLM what the tool does, when to use it, and what parameters it takes.\n",
        "\n",
        "This tutorial follows the [Anthropic documentation on tool use](https://docs.claude.com/en/docs/agents-and-tools/tool-use/overview). If you're using a different LLM API than this tutorial, I recommend to check out your LLM providers documentation on tool use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "200ad721",
      "metadata": {
        "id": "200ad721"
      },
      "outputs": [],
      "source": [
        "class CalculatorTool():\n",
        "    \"\"\"A tool for performing mathematical calculations\"\"\"\n",
        "\n",
        "    def get_schema(self):\n",
        "        return {\n",
        "            \"name\": \"calculator\",\n",
        "            \"description\": \"Performs basic mathematical calculations, use also for simple additions\",\n",
        "            \"input_schema\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"expression\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Mathematical expression to evaluate (e.g., '2+2', '10*5')\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"expression\"]\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def execute(self, expression):\n",
        "        \"\"\"\n",
        "        Evaluate mathematical expressions.\n",
        "        WARNING: This tutorial uses eval() for simplicity but it is not recommended for production use.\n",
        "\n",
        "        Args:\n",
        "            expression (str): The mathematical expression to evaluate\n",
        "        Returns:\n",
        "            float: The result of the evaluation\n",
        "        \"\"\"\n",
        "        try:\n",
        "            result = eval(expression)\n",
        "            return {\"result\": result}\n",
        "        except:\n",
        "            return {\"error\": \"Invalid mathematical expression\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a9f23b4",
      "metadata": {
        "id": "9a9f23b4"
      },
      "source": [
        "Note, that in this tutorial, we are just implementing a single tool. In production code, you'd typically use an abstract base class to ensure a consistent interface across tools."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "olL2xznWkj7u",
      "metadata": {
        "id": "olL2xznWkj7u"
      },
      "source": [
        "Let's test if the calculator function works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "B6n4v-kukkR7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6n4v-kukkR7",
        "outputId": "f9e054bb-3d40-4f5f-b936-78a006f56dbf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'result': 77585.1801}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "calculator_tool = CalculatorTool()\n",
        "\n",
        "calculator_tool.execute(\"157.09 * 493.89\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8lvVG8R3vVSi",
      "metadata": {
        "id": "8lvVG8R3vVSi"
      },
      "source": [
        "Now that we have a `CalculatorTool`, let's add tool use capabilities to our agent, in three steps:\n",
        "\n",
        "1. Add `tools` and `tool_map` attributes to store available tools\n",
        "2. Add the private `_get_tool_schemas()` method to extract tool schemas\n",
        "3. Add tool handling logic to the `create` method to detect tool use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dhY1LyDlkrMH",
      "metadata": {
        "id": "dhY1LyDlkrMH"
      },
      "outputs": [],
      "source": [
        "class Agent:\n",
        "    \"\"\"A simple AI agent that can use tools to answer questions in a multi-turn conversation\"\"\"\n",
        "\n",
        "    def __init__(self, tools):\n",
        "        self.client = anthropic.Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
        "        self.model = \"claude-sonnet-4-20250514\"\n",
        "        self.system_message = \"You are a helpful assistant that breaks down problems into steps and solves them systematically.\"\n",
        "        self.messages = []\n",
        "        self.tools = tools\n",
        "        self.tool_map = {tool.get_schema()[\"name\"]: tool for tool in tools}\n",
        "\n",
        "    def _get_tool_schemas(self):\n",
        "        \"\"\"Get tool schemas for all registered tools\"\"\"\n",
        "        return [tool.get_schema() for tool in self.tools]\n",
        "\n",
        "    def chat(self, message):\n",
        "        \"\"\"Process a user message and return a response\"\"\"\n",
        "\n",
        "        # Store user input in short-term memory\n",
        "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "        response = self.client.messages.create(\n",
        "            model=self.model,\n",
        "            max_tokens=1024,\n",
        "            system=self.system_message,\n",
        "            tools=self._get_tool_schemas() if self.tools else None,\n",
        "            messages=self.messages,\n",
        "            temperature=0.1,\n",
        "        )\n",
        "\n",
        "        # Store assistant's response in short-term memory\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": response.content})\n",
        "\n",
        "        return response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae2d1183",
      "metadata": {
        "id": "ae2d1183"
      },
      "source": [
        "Let's give it a try."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f2095cc8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2095cc8",
        "outputId": "3ba2efc6-e8d6-4c97-deb8-a6e6ebfc055a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('id', 'msg_01BzC2FerKEr8rC1wGfaMiNK')\n",
            "('content', [TextBlock(citations=None, text=\"I'll calculate 157.09 * 493.89 for you.\", type='text'), ToolUseBlock(id='toolu_017NhVhd5wYWdEw7fFRPHyXL', input={'expression': '157.09 * 493.89'}, name='calculator', type='tool_use')])\n",
            "('model', 'claude-sonnet-4-20250514')\n",
            "('role', 'assistant')\n",
            "('stop_reason', 'tool_use')\n",
            "('stop_sequence', None)\n",
            "('type', 'message')\n",
            "('usage', Usage(cache_creation=CacheCreation(ephemeral_1h_input_tokens=0, ephemeral_5m_input_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=433, output_tokens=77, server_tool_use=None, service_tier='standard'))\n"
          ]
        }
      ],
      "source": [
        "calculator_tool = CalculatorTool()\n",
        "agent = Agent(tools=[calculator_tool])\n",
        "\n",
        "response = agent.chat(\"What is 157.09 * 493.89?\")\n",
        "\n",
        "for block in response:\n",
        "  print(block)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dvQhdaqmvZwd",
      "metadata": {
        "id": "dvQhdaqmvZwd"
      },
      "source": [
        "As you can see in the response, the agent answers with \"I'll calculate 157.09 * 493.89 for you.\" but instead of calculating the expression itself, it stops with `stop_reason` being `tool_use`. This means, that the agent is waiting for the user to execute the tool and return the result from the tool to the agent.\n",
        "\n",
        "But now, the agent has responded that it needs help with executing the tool and is waiting. This is where the final component of the loop comes into play."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88ffccbb",
      "metadata": {
        "id": "88ffccbb"
      },
      "source": [
        "### Component 4: Agent Loop\n",
        "\n",
        "You might have already heard people say that [\"Agents are models using tools in a loop\"](https://youtu.be/D7_ipDqhtwk?si=KCpWMv_Heux3PVeK&t=356). Without the loop, the agent can only handle single-turn without multi-turn interactions.\n",
        "\n",
        "I really like this pseudo code by [Barry Zhan, Anthropic](https://youtu.be/D7_ipDqhtwk?si=KCpWMv_Heux3PVeK&t=356), showing that agents are just LLMs making decisions in a loop, observing results, and deciding what to do next.\n",
        "\n",
        "```python\n",
        "env = Environment()\n",
        "tools = Tools(env)\n",
        "system_prompt = \"Goals, constraints, and how to act\"\n",
        "\n",
        "while True:\n",
        "  action = llm.run(system_prompt + env.state)\n",
        "  env.state = tools.run(action)\n",
        "```\n",
        "\n",
        "For this simple agent implementation, that means, we have the following flow:\n",
        "\n",
        "1. User sends message to agent\n",
        "2. Agent decides it needs a tool and responds with a `stop_reason` of `tool_use` and a `tool_use`block with the tool name and parameters. It's saying \"I'm pausing for you to execute this tool with these parameters\".\n",
        "3. The user executes the tool and sends the tool result back to the agent in a follow-up message\n",
        "5. The agent continues and gives the final response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ir0vAGMPf1CV",
      "metadata": {
        "id": "ir0vAGMPf1CV"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def run_agent(user_input, max_turns=10):\n",
        "  calculator_tool = CalculatorTool()\n",
        "  agent = Agent(tools=[calculator_tool])\n",
        "\n",
        "  i = 0\n",
        "\n",
        "  while i < max_turns: # It's safer to use max_turns rather than while True\n",
        "    i += 1\n",
        "    print(f\"\\nIteration {i}:\")\n",
        "\n",
        "    print(f\"User input: {user_input}\")\n",
        "    response = agent.chat(user_input)\n",
        "    print(f\"Agent output: {response.content[0].text}\")\n",
        "\n",
        "    # Handle tool use if present\n",
        "    if response.stop_reason == \"tool_use\":\n",
        "\n",
        "        # Process all tool uses in the response\n",
        "        tool_results = []\n",
        "        for content_block in response.content:\n",
        "            if content_block.type == \"tool_use\":\n",
        "                tool_name = content_block.name\n",
        "                tool_input = content_block.input\n",
        "\n",
        "                print(f\"Using tool {tool_name} with input {tool_input}\")\n",
        "\n",
        "                # Execute the tool\n",
        "                tool = agent.tool_map[tool_name]\n",
        "                tool_result = tool.execute(**tool_input)\n",
        "\n",
        "                tool_results.append({\n",
        "                    \"type\": \"tool_result\",\n",
        "                    \"tool_use_id\": content_block.id,\n",
        "                    \"content\": json.dumps(tool_result)\n",
        "                })\n",
        "                print(f\"Tool result: {tool_result}\")\n",
        "\n",
        "        # Add tool results to conversation\n",
        "        user_input = tool_results\n",
        "    else:\n",
        "      return response.content[0].text\n",
        "\n",
        "  return\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf16f623",
      "metadata": {
        "id": "cf16f623"
      },
      "source": [
        "## Testing the Implemented AI Agent\n",
        "\n",
        "Let's test the implemented AI agent with a few example test cases."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73e9e695",
      "metadata": {
        "id": "73e9e695"
      },
      "source": [
        "### Test 1: General question (no tool use)\n",
        "\n",
        "This test demonstrates the agent's ability to answer a simple, general question that does not require the use of any external tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "loZgyGmZ4YNr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loZgyGmZ4YNr",
        "outputId": "59fff72f-12ec-44c1-b9da-93ba8d37ecf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 1:\n",
            "User input: I have 4 apples. How many do you have?\n",
            "Agent output: I don't have any apples since I'm an AI assistant - I don't have a physical form or possessions. But I can help you with calculations involving your 4 apples if you need!\n",
            "\n",
            "Is there something specific you'd like to calculate or figure out with your 4 apples?\n"
          ]
        }
      ],
      "source": [
        "response = run_agent(\"I have 4 apples. How many do you have?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a46e298",
      "metadata": {
        "id": "5a46e298"
      },
      "source": [
        "### Test 2: Tool Use\n",
        "\n",
        "This test demonstrates how the agent understands that it needs to use a tool to to solve a specific task and uses the `CalculatorTool` to get the correct result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f119QvtT4Wzi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f119QvtT4Wzi",
        "outputId": "7c3d1556-40b9-40b8-e0cc-f024562fa85e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 1:\n",
            "User input: What is 157.09 * 493.89?\n",
            "Agent output: I'll calculate 157.09 * 493.89 for you.\n",
            "Using tool calculator with input {'expression': '157.09 * 493.89'}\n",
            "Tool result: {'result': 77585.1801}\n",
            "\n",
            "Iteration 2:\n",
            "User input: [{'type': 'tool_result', 'tool_use_id': 'toolu_01FC9yLWt2Cf6a8zLGhj7ZJz', 'content': '{\"result\": 77585.1801}'}]\n",
            "Agent output: The result of 157.09 * 493.89 is **77,585.1801**.\n"
          ]
        }
      ],
      "source": [
        "response = run_agent(\"What is 157.09 * 493.89?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a5857a0",
      "metadata": {
        "id": "8a5857a0"
      },
      "source": [
        "### Test 3: Step-by-step tool use\n",
        "\n",
        "This test demonstrates the agent's ability to break down a more complex problem into smaller steps and use the `CalculatorTool` multiple times within a single conversation to arrive at the final answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "-Lkv6mI94Zmr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Lkv6mI94Zmr",
        "outputId": "a2fbb58d-a7bb-426a-eebc-76eb44cd0d54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 1:\n",
            "User input: If my brother is 32 years younger than my mother and my mother is 30 years older than me and I am 20, how old is my brother?\n",
            "Agent output: I'll solve this step by step using the given information.\n",
            "\n",
            "Given:\n",
            "- You are 20 years old\n",
            "- Your mother is 30 years older than you\n",
            "- Your brother is 32 years younger than your mother\n",
            "\n",
            "Let me calculate your mother's age first:\n",
            "Using tool calculator with input {'expression': '20 + 30'}\n",
            "Tool result: {'result': 50}\n",
            "\n",
            "Iteration 2:\n",
            "User input: [{'type': 'tool_result', 'tool_use_id': 'toolu_01WPMQRzCi4roua9vQ7qXeCR', 'content': '{\"result\": 50}'}]\n",
            "Agent output: So your mother is 50 years old.\n",
            "\n",
            "Now I'll calculate your brother's age:\n",
            "Using tool calculator with input {'expression': '50 - 32'}\n",
            "Tool result: {'result': 18}\n",
            "\n",
            "Iteration 3:\n",
            "User input: [{'type': 'tool_result', 'tool_use_id': 'toolu_01UL7n7a85XJUn7Tgk8kiHhX', 'content': '{\"result\": 18}'}]\n",
            "Agent output: Your brother is 18 years old.\n",
            "\n",
            "To summarize:\n",
            "- You: 20 years old\n",
            "- Your mother: 50 years old (30 years older than you)\n",
            "- Your brother: 18 years old (32 years younger than your mother)\n"
          ]
        }
      ],
      "source": [
        "response = run_agent(\"If my brother is 32 years younger than my mother and my mother is 30 years older than me and I am 20, how old is my brother?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c00bf35d",
      "metadata": {
        "id": "c00bf35d"
      },
      "source": [
        "## Summary\n",
        "\n",
        "This tutorial showed you how you can implement a minimal AI agent from scratch using just an LLM API without any frameworks.\n",
        "Hopefully, you now understand the fundamentals of what happens under the hood of an AI agent and what people mean, when they say \"Agents are models using tools in a loop\".\n",
        "\n",
        "You can find this notebook in this [GitHub repository](https://github.com/iamleonie/website/blob/main/blog/ai-agent-from-scratch-in-python.ipynb)\n",
        "\n",
        "As a next step, you can refer to the following resources to learn more about how to implement different agent workflows."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a200371",
      "metadata": {
        "id": "8a200371"
      },
      "source": [
        "## Resources\n",
        "\n",
        "- [Anthropic's Building Effective Agents Cookbook](https://github.com/anthropics/claude-cookbooks/tree/main/patterns/agents)\n",
        "- [Build an AI Agent from SCRATCH with Python! (No Frameworks) by Aaron Dunn](https://www.youtube.com/watch?v=mYo7UFwnW1k)\n",
        "- [Building Effective LLM Workflows in Pure Python by Dave Ebbelaar](https://github.com/daveebbelaar/ai-cookbook/tree/main/patterns)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
