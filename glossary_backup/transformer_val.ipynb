{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yGC3oshodPmd"
   },
   "source": [
    "---\n",
    "title: \"Transformer Validation Pipeline\"\n",
    "description: \"Complete validation pipeline for transformer models using PyTorch's nn.Transformer\"\n",
    "date: \"2025-08-01\"\n",
    "bread-crumbs: true\n",
    "back-to-top-navigation: true\n",
    "toc: true\n",
    "toc-depth: 3\n",
    "---\n",
    "\n",
    "This section implements a complete English-French translator using PyTorch's built-in `nn.Transformer` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KmJ1-XcgdPmf"
   },
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, let's set up our environment. \n",
    "We're using PyTorch's built-in transformer (no need to reinvent the wheel), plus some essential libraries for data handling and visualization.\n",
    "\n",
    "We set random seeds for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0POmFykdPmg",
    "outputId": "0697c8d3-b61a-4555-b15d-9172bb5918bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.13.1\n",
      "CUDA available: False\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from typing import List, Tuple, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5j-3vvdmdPmh"
   },
   "source": [
    "## Preparing Dataset\n",
    "\n",
    "Always start with your data. \n",
    "Let's load our English-French translation pairs and understand what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PIvUAAY7CN2z",
    "outputId": "775ffe4c-f930-43f5-e803-86172688d652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from local file: english_french_translations.csv\n",
      "Loaded 1000 translation pairs from CSV file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English words/sentences</th>\n",
       "      <th>French words/sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Take a seat.</td>\n",
       "      <td>Prends place !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I wish Tom was here.</td>\n",
       "      <td>J'aimerais que Tom soit l√†.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How did the audition go?</td>\n",
       "      <td>Comment s'est pass√©e l'audition¬†?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've no friend to talk to about my problems.</td>\n",
       "      <td>Je n'ai pas d'ami avec lequel je puisse m'entr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I really like this skirt. Can I try it on?</td>\n",
       "      <td>J'aime beaucoup cette jupe, puis-je l'essayer‚ÄØ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        English words/sentences  \\\n",
       "0                                  Take a seat.   \n",
       "1                          I wish Tom was here.   \n",
       "2                      How did the audition go?   \n",
       "3  I've no friend to talk to about my problems.   \n",
       "4    I really like this skirt. Can I try it on?   \n",
       "\n",
       "                              French words/sentences  \n",
       "0                                     Prends place !  \n",
       "1                        J'aimerais que Tom soit l√†.  \n",
       "2                  Comment s'est pass√©e l'audition¬†?  \n",
       "3  Je n'ai pas d'ami avec lequel je puisse m'entr...  \n",
       "4    J'aime beaucoup cette jupe, puis-je l'essayer‚ÄØ?  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download data\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set environment flag - change this to True when running in Colab\n",
    "COLAB = False\n",
    "\n",
    "if COLAB:\n",
    "    # Original Colab code using Kaggle Hub\n",
    "    import kagglehub\n",
    "    from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "    # Set the path to the file you'd like to load\n",
    "    file_path = \"eng_-french.csv\"\n",
    "\n",
    "    # Load the latest version\n",
    "    df = kagglehub.load_dataset(\n",
    "      KaggleDatasetAdapter.PANDAS,\n",
    "      \"devicharith/language-translation-englishfrench\",\n",
    "      file_path,\n",
    "      # Provide any additional arguments like\n",
    "      # sql_query or pandas_kwargs. See the\n",
    "      # documenation for more information:\n",
    "      # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    "    )\n",
    "\n",
    "    # Shuffle the dataframe with a fixed seed\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    df = df[:1000]\n",
    "    \n",
    "else:\n",
    "    # Local file loading\n",
    "    csv_file_path = \"english_french_translations.csv\"\n",
    "    \n",
    "    if os.path.exists(csv_file_path):\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"CSV file '{csv_file_path}' not found\")\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's prepare our translation pairs and split them into training and validation sets. The 80/20 split is a classic ratio that gives enough training data while preserving examples for unbiased evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3aFmfBmAdPmi",
    "outputId": "cca875ec-f65e-45b7-d240-fde18f5490cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs: 1000\n",
      "Training pairs: 800\n",
      "Validation pairs: 200\n",
      "\\nExample pairs:\n",
      "1. English: 'Take a seat.' -> French: 'Prends place !'\n",
      "2. English: 'I wish Tom was here.' -> French: 'J'aimerais que Tom soit l√†.'\n",
      "3. English: 'How did the audition go?' -> French: 'Comment s'est pass√©e l'audition¬†?'\n"
     ]
    }
   ],
   "source": [
    "# Use the downloaded data from the dataframe 'df'\n",
    "# Assuming 'df' has columns named 'English words/sentences' and 'French words/sentences'\n",
    "translation_pairs = []\n",
    "for index, row in df.iterrows():\n",
    "    english_sentence = row['English words/sentences']\n",
    "    french_sentence = row['French words/sentences']\n",
    "    translation_pairs.append((english_sentence, french_sentence))\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_size = int(0.8 * len(translation_pairs))\n",
    "train_pairs = translation_pairs[:train_size]\n",
    "val_pairs = translation_pairs[train_size:]\n",
    "\n",
    "print(f\"Total pairs: {len(translation_pairs)}\")\n",
    "print(f\"Training pairs: {len(train_pairs)}\")\n",
    "print(f\"Validation pairs: {len(val_pairs)}\")\n",
    "print(f\"\\\\nExample pairs:\")\n",
    "for i, (en, fr) in enumerate(train_pairs[:3]):\n",
    "    print(f\"{i+1}. English: '{en}' -> French: '{fr}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TBaLAESdPmi"
   },
   "source": [
    "## Data Preprocessing and Tokenization\n",
    "\n",
    "Since computers don't understand words,our job is to convert text into integers that the transformer can process.\n",
    "\n",
    "Think of vocabulary as a bilingual dictionary where every unique word gets a number:\n",
    "- \"hello\" ‚Üí 42\n",
    "- \"bonjour\" ‚Üí 17\n",
    "- \"world\" ‚Üí 1337\n",
    "\n",
    "**Critical special tokens** (these aren't arbitrary - they're mathematically necessary):\n",
    "- `<pad>` (0): Padding token - makes all sequences the same length\n",
    "- `<sos>` (1): Start of sequence - tells the decoder \"begin translation\"\n",
    "- `<eos>` (2): End of sequence - tells the decoder \"stop generating\"  \n",
    "- `<unk>` (3): Unknown token - handles words not seen during training\n",
    "\n",
    "The Data Flow Pipeline:\n",
    "```\n",
    "Raw text ‚Üí Tokenization ‚Üí Vocabulary lookup ‚Üí Integer sequences ‚Üí Tensor batches\n",
    "```\n",
    "\n",
    "We use 80/20 split - a classic ratio that gives enough training data while preserving examples for unbiased evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sIDhkVaCdPmi",
    "outputId": "a8534da1-c900-44eb-c5a9-eb8f0327b246"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vocabularies...\n",
      "English vocabulary size: 1481\n",
      "French vocabulary size: 1790\n",
      "\\nEnglish words: ['<pad>', '<sos>', '<eos>', '<unk>', 'take', 'a', 'seat.', 'i', 'wish', 'tom']\n",
      "French words: ['<pad>', '<sos>', '<eos>', '<unk>', 'prends', 'place', '!', \"j'aimerais\", 'que', 'tom']\n",
      "\\nTokenization test (using training vocabulary words):\n",
      "'I wish Tom' -> [1, 7, 8, 9, 2]\n",
      "'Je prends place' -> [1, 17, 4, 5, 2]\n",
      "Back to text: 'i wish tom'\n",
      "Back to text: 'je prends place'\n",
      "\\nüìù Note: Previously 'Hello world' became <unk> <unk> because\n",
      "those words don't exist in our training data. The vocabulary only\n",
      "contains words seen during training from the 1000 translation pairs.\n"
     ]
    }
   ],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.word2idx = {\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2, \"<unk>\": 3}\n",
    "        self.idx2word = {0: \"<pad>\", 1: \"<sos>\", 2: \"<eos>\", 3: \"<unk>\"}\n",
    "        self.word_count = {}\n",
    "        self.n_words = 4  # Count default tokens\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        # Simple split by space for now - can be improved with a proper tokenizer\n",
    "        for word in sentence.lower().split():\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            self.word2idx[word] = self.n_words\n",
    "            self.idx2word[self.n_words] = word\n",
    "            self.word_count[word] = 1\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word_count[word] += 1\n",
    "\n",
    "    def sentence_to_indices(self, sentence, add_eos=True):\n",
    "        indices = [self.word2idx[\"<sos>\"]]\n",
    "        for word in sentence.lower().split():\n",
    "            if word in self.word2idx:\n",
    "                indices.append(self.word2idx[word])\n",
    "            else:\n",
    "                indices.append(self.word2idx[\"<unk>\"])\n",
    "        if add_eos:\n",
    "            indices.append(self.word2idx[\"<eos>\"])\n",
    "        return indices\n",
    "\n",
    "    def indices_to_sentence(self, indices):\n",
    "        words = []\n",
    "        for idx in indices:\n",
    "            if idx == self.word2idx[\"<eos>\"]:\n",
    "                break\n",
    "            if idx not in [self.word2idx[\"<pad>\"], self.word2idx[\"<sos>\"]]:\n",
    "                words.append(self.idx2word[idx])\n",
    "        return \" \".join(words)\n",
    "\n",
    "# Create vocabularies\n",
    "english_vocab = Vocabulary()\n",
    "french_vocab = Vocabulary()\n",
    "\n",
    "# Build vocabularies from training data\n",
    "for en_sentence, fr_sentence in train_pairs: \n",
    "    english_vocab.add_sentence(en_sentence)\n",
    "    french_vocab.add_sentence(fr_sentence)\n",
    "\n",
    "print(f\"English vocabulary size: {english_vocab.n_words}\")\n",
    "print(f\"French vocabulary size: {french_vocab.n_words}\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Source texts**: The input language (English sentences we want to translate)\n",
    "**Target texts**: The output language (French sentences we want to generate)\n",
    "\n",
    "Example:\n",
    "```\n",
    "Source: \"I wish Tom was here.\"     ‚Üí [1, 8, 9, 10, 11, 2]  (English tokens)\n",
    "Target: \"J'aimerais que Tom soit l√†.\" ‚Üí [1, 7, 8, 9, 10, 11, 2]  (French tokens)\n",
    "```\n",
    "\n",
    "Both get converted to integer sequences using their respective vocabularies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test tokenization using actual words from our training vocabulary\n",
    "test_en = \"I wish Tom was here.\"  \n",
    "test_fr = \"J'aimerais que Tom soit l√†.\"  \n",
    "en_indices = english_vocab.sentence_to_indices(test_en)\n",
    "fr_indices = french_vocab.sentence_to_indices(test_fr) \n",
    "\n",
    "print(f\"'{test_en}' -> {en_indices}\")\n",
    "print(f\"'{test_fr}' -> {fr_indices}\") \n",
    "print(f\"Back to text: '{english_vocab.indices_to_sentence(en_indices)}'\")\n",
    "print(f\"Back to text: '{french_vocab.indices_to_sentence(fr_indices)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating PyTorch Datasets\n",
    "\n",
    "Now we need to package our data into PyTorch's `Dataset` and `DataLoader` classes. This handles the conversion from text to tensors and ensures efficient batching during training.\n",
    "\n",
    "\n",
    "### Padding: Making Batches Uniform\n",
    "\n",
    "**The problem**: Neural networks need tensors of consistent size, but sentences have different lengths:\n",
    "- \"Take a seat.\" ‚Üí 4 tokens\n",
    "- \"I've no friend to talk to about my problems.\" ‚Üí 10 tokens\n",
    "\n",
    "**The solution**: Pad shorter sequences with `<pad>` tokens (index 0) to match the longest sequence in each batch:\n",
    "\n",
    "```\n",
    "Batch before padding:\n",
    "[1, 4, 5, 6, 2]           # \"take a seat.\" (5 tokens)\n",
    "[1, 8, 9, 10, 11, 12, 13, 14, 15, 16, 2]  # longer sentence (11 tokens)\n",
    "\n",
    "Batch after padding:\n",
    "[1, 4, 5, 6, 2, 0, 0, 0, 0, 0, 0]         # padded to 11 tokens\n",
    "[1, 8, 9, 10, 11, 12, 13, 14, 15, 16, 2]  # already 11 tokens\n",
    "```\n",
    "\n",
    "The `collate_fn` takes a batch of these objects and creates padded tensors for efficient GPU processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bu7CNENddPmj",
    "outputId": "0acb37fb-2a21-452b-fa9e-f1e241ad4c86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batches: 200\n",
      "Validation batches: 50\n",
      "\\nTesting data loader:\n",
      "Source batch shape: torch.Size([4, 11])\n",
      "Target batch shape: torch.Size([4, 11])\n",
      "Source texts: [\"Don't commit yourself.\", 'With a little more effort, he would have succeeded.', 'Most Japanese houses are built of wood.', \"You're very generous.\"]\n",
      "Target texts: [\"Ne t'engage pas.\", \"En faisant un peu plus d'effort, il aurait r√©ussi.\", 'La plupart des maisons japonaises sont faites en bois.', 'Tu es fort g√©n√©reux.']\n"
     ]
    }
   ],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, pairs, src_vocab, tgt_vocab):\n",
    "        self.pairs = pairs\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_sentence, tgt_sentence = self.pairs[idx]\n",
    "\n",
    "        # Convert to indices\n",
    "        src_indices = self.src_vocab.sentence_to_indices(src_sentence)\n",
    "        tgt_indices = self.tgt_vocab.sentence_to_indices(tgt_sentence)\n",
    "\n",
    "        return {\n",
    "            'src': torch.tensor(src_indices, dtype=torch.long),\n",
    "            'tgt': torch.tensor(tgt_indices, dtype=torch.long),\n",
    "            'src_text': src_sentence,\n",
    "            'tgt_text': tgt_sentence\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function to pad sequences in a batch\"\"\"\n",
    "    src_sequences = [item['src'] for item in batch]\n",
    "    tgt_sequences = [item['tgt'] for item in batch]\n",
    "    src_texts = [item['src_text'] for item in batch]\n",
    "    tgt_texts = [item['tgt_text'] for item in batch]\n",
    "\n",
    "    # Pad sequences\n",
    "    src_padded = pad_sequence(src_sequences, batch_first=True, padding_value=0)\n",
    "    tgt_padded = pad_sequence(tgt_sequences, batch_first=True, padding_value=0)\n",
    "\n",
    "    return {\n",
    "        'src': src_padded,\n",
    "        'tgt': tgt_padded,\n",
    "        'src_text': src_texts,\n",
    "        'tgt_text': tgt_texts\n",
    "    }\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TranslationDataset(train_pairs, english_vocab, french_vocab)\n",
    "val_dataset = TranslationDataset(val_pairs, english_vocab, french_vocab)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source batch shape: torch.Size([4, 13])\n",
      "Target batch shape: torch.Size([4, 16])\n",
      "Source indices: tensor([[   1,   39,  619,  266,  273, 1475, 1476,  298,   39,  409,   14,  312,\n",
      "            2],\n",
      "        [   1,    7,  218,  794,   52,  163,  867,    2,    0,    0,    0,    0,\n",
      "            0],\n",
      "        [   1,   86,    5,  246,  184,   14,  247,    2,    0,    0,    0,    0,\n",
      "            0],\n",
      "        [   1,  522,   14,  629,    2,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0]])\n",
      "Target indices: tensor([[   1,  117, 1195,  359,  162,  298,   56,  323, 1783,  187,  125, 1784,\n",
      "           69,   70,  689,    2],\n",
      "        [   1,   17,  441,   19,  187,  908,    8,  196, 1016,   25, 1017,    2,\n",
      "            0,    0,    0,    0],\n",
      "        [   1,  117,  247,  167,  270,  175,  271,    2,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   1,  574,   73,  700,    2,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]])\n",
      "Source texts: ['You must have women throwing themselves at you all the time.', \"I can't believe that just worked.\", \"You're a victim of the system.\", 'Leave the bottle.']\n",
      "Target texts: ['Vous devez avoir des femmes qui se pendent √† votre cou tout le temps.', \"Je n'arrive pas √† croire que √ßa vienne de fonctionner.\", 'Vous √™tes une victime du syst√®me.', 'Laisse la bouteille.']\n"
     ]
    }
   ],
   "source": [
    "# Get a sample from the dataset\n",
    "for batch in train_loader:\n",
    "    print(f\"Source batch shape: {batch['src'].shape}\")\n",
    "    print(f\"Target batch shape: {batch['tgt'].shape}\")\n",
    "    print(f\"Source indices: {batch['src']}\")\n",
    "    print(f\"Target indices: {batch['tgt']}\")\n",
    "    print(f\"Source texts: {batch['src_text']}\")\n",
    "    print(f\"Target texts: {batch['tgt_text']}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len=5000, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Create positional encoding matrix\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        position = torch.arange(0, max_seq_len).unsqueeze(1).float()\n",
    "\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() *\n",
    "                           -(math.log(10000.0) / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        x = x + self.pe[:, :seq_len]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXpRnKxYdPmk"
   },
   "source": [
    "### Building the Complete Transformer Model\n",
    "\n",
    "**Why separate embeddings?** PyTorch's `nn.Transformer` is just the core attention mechanism - it expects continuous vectors as input, not discrete tokens. We need embeddings to convert our token indices (like 42 for \"hello\") into dense 256-dimensional vectors that can participate in attention.\n",
    "\n",
    "- **Source vs Target Embeddings**: English and French have different vocabularies (1481 vs 1790 words), so they need separate embedding matrices. The English embedding learns that token 42 might represent \"hello\", while the French embedding learns that token 17 represents \"bonjour\".\n",
    "\n",
    "- **Causal mask**: Prevents the decoder from \"cheating\" by looking at future tokens during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rj7P3RJ9dPml",
    "outputId": "6236535a-5d13-477f-a6a3-262dfcd53668"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created with 5,252,094 trainable parameters\n",
      "Model device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 src_vocab_size, \n",
    "                 tgt_vocab_size, \n",
    "                 d_model=256, \n",
    "                 nhead=8,\n",
    "                 num_encoder_layers=3, \n",
    "                 num_decoder_layers=3, \n",
    "                 dim_feedforward=512,\n",
    "                 dropout=0.1, \n",
    "                 max_seq_len=100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.src_vocab_size = src_vocab_size\n",
    "        self.tgt_vocab_size = tgt_vocab_size\n",
    "\n",
    "        # Embeddings\n",
    "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        # Positional encoding\n",
    "        self.pos_encoding = PositionalEncoding(d_model, max_seq_len, dropout)\n",
    "\n",
    "        # Transformer\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # Output projection\n",
    "        self.output_projection = nn.Linear(d_model, tgt_vocab_size)\n",
    "\n",
    "        # Initialize parameters\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.src_embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.tgt_embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.output_projection.bias.data.zero_()\n",
    "        self.output_projection.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def create_mask(self, src, tgt):\n",
    "        src_seq_len = src.shape[1]\n",
    "        tgt_seq_len = tgt.shape[1]\n",
    "\n",
    "        # Create causal mask for target\n",
    "        tgt_mask = torch.triu(torch.ones(tgt_seq_len, tgt_seq_len) * float('-inf'), diagonal=1)\n",
    "\n",
    "        # Create padding masks\n",
    "        src_padding_mask = (src == 0)  # True for padding tokens\n",
    "        tgt_padding_mask = (tgt == 0)  # True for padding tokens\n",
    "\n",
    "        return tgt_mask.to(src.device), src_padding_mask, tgt_padding_mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        # Create masks\n",
    "        tgt_mask, src_padding_mask, tgt_padding_mask = self.create_mask(src, tgt)\n",
    "\n",
    "        # Embed and add positional encoding\n",
    "        src_emb = self.pos_encoding(self.src_embedding(src) * math.sqrt(self.d_model))\n",
    "        tgt_emb = self.pos_encoding(self.tgt_embedding(tgt) * math.sqrt(self.d_model))\n",
    "\n",
    "        # Transformer forward pass\n",
    "        output = self.transformer(\n",
    "            src=src_emb,\n",
    "            tgt=tgt_emb,\n",
    "            tgt_mask=tgt_mask,\n",
    "            src_key_padding_mask=src_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_padding_mask\n",
    "        )\n",
    "\n",
    "        # Project to vocabulary\n",
    "        return self.output_projection(output)\n",
    "\n",
    "# Model hyperparameters\n",
    "d_model = 256\n",
    "nhead = 8\n",
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 3\n",
    "dim_feedforward = 512\n",
    "dropout = 0.1\n",
    "\n",
    "# Create model\n",
    "model = TransformerModel(\n",
    "    src_vocab_size=english_vocab.n_words,\n",
    "    tgt_vocab_size=french_vocab.n_words, # Changed from german_vocab.n_words\n",
    "    d_model=d_model,\n",
    "    nhead=nhead,\n",
    "    num_encoder_layers=num_encoder_layers,\n",
    "    num_decoder_layers=num_decoder_layers,\n",
    "    dim_feedforward=dim_feedforward,\n",
    "    dropout=dropout\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model created with {sum(p.numel() for p in model.parameters() if p.requires_grad):,} trainable parameters\")\n",
    "print(f\"Model device: {next(model.parameters()).device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Model Forward Pass\n",
    "\n",
    "Before training, we always test that our model works correctly with real data. This code snippet verifies:\n",
    "\n",
    "1. **Tensor shapes**: Ensures our model produces the expected output dimensions\n",
    "2. **Teacher forcing setup**: Shows how we shift target sequences (input vs output targets)\n",
    "3. **Device compatibility**: Confirms tensors are on the correct GPU/CPU\n",
    "4. **No runtime errors**: Catches issues before expensive training begins\n",
    "\n",
    "The target shifting is crucial: during training, the decoder sees `<sos> Je suis` and predicts `Je suis <eos>`. This teaches the model to generate each token given the previous context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source shape: torch.Size([4, 11])\n",
      "Target input shape: torch.Size([4, 11])\n",
      "Target output shape: torch.Size([4, 11])\n",
      "Model output shape: torch.Size([4, 11, 1790])\n",
      "‚úÖ Model forward pass successful!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test model with a batch\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in train_loader:\n",
    "        src = batch['src'].to(device)\n",
    "        tgt = batch['tgt'].to(device)\n",
    "\n",
    "        # For training, we use target input (shifted by one position)\n",
    "        tgt_input = tgt[:, :-1]  # Remove last token\n",
    "        tgt_output = tgt[:, 1:]  # Remove first token (SOS)\n",
    "\n",
    "        print(f\"Source shape: {src.shape}\")\n",
    "        print(f\"Target input shape: {tgt_input.shape}\")\n",
    "        print(f\"Target output shape: {tgt_output.shape}\")\n",
    "\n",
    "        output = model(src, tgt_input)\n",
    "        print(f\"Model output shape: {output.shape}\")\n",
    "        print(\"‚úÖ Model forward pass successful!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dO5TWWlwdPmm"
   },
   "source": [
    "## Training Loop\n",
    "\n",
    "Time to teach our transformer to translate!\n",
    "\n",
    "**Input to decoder**: `<sos> Je suis heureux`\n",
    "**Target for loss**: `Je suis heureux <eos>`\n",
    "\n",
    "Notice the shift - the model learns to predict each token given all previous tokens.\n",
    "\n",
    "\n",
    "- CrossEntropyLoss: The model outputs probability distributions over the vocabulary (~1790 French words). We want high probability for the correct word, low for others.\n",
    "\n",
    "Training Hyperparameters:\n",
    "\n",
    "- **Learning rate**: 0.0001 - small enough for stable training, large enough for progress\n",
    "- **Gradient clipping**: Max norm 1.0 - prevents exploding gradients that can destroy training\n",
    "- **Scheduler**: ReduceLROnPlateau - when validation loss plateaus, reduce learning rate by 50%\n",
    "- **Batch size**: 4 - small due to memory constraints, larger would be better\n",
    "\n",
    "\n",
    "**Good signs**:\n",
    "- Training loss decreasing steadily (6.0 ‚Üí 2.8)\n",
    "- Validation loss following training loss initially\n",
    "- No NaN or infinite losses\n",
    "\n",
    "**Warning signs**:\n",
    "- Large gap between train/validation loss (overfitting - we see this!)\n",
    "- Validation loss increasing while training decreases (definite overfitting)\n",
    "- Loss oscillating wildly (learning rate too high)\n",
    "\n",
    "**Expected behavior**: With only 1000 examples, the model will overfit (memorize training data). This is normal and educational - you're seeing why large datasets matter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5FP6cXZLdPmm",
    "outputId": "fe8c94cc-dd1e-46fd-91bd-1260cb9b59b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 10 epochs...\n",
      "Learning rate: 0.0001\n",
      "Epoch [1/10], Batch [100/200], Loss: 6.4381\n",
      "Epoch [1/10], Batch [200/200], Loss: 6.2279\n",
      "Epoch [1/10] - Train Loss: 6.2279, Val Loss: 5.8683\n",
      "--------------------------------------------------\n",
      "Epoch [2/10], Batch [100/200], Loss: 5.5059\n",
      "Epoch [2/10], Batch [200/200], Loss: 5.4847\n",
      "Epoch [2/10] - Train Loss: 5.4847, Val Loss: 5.7588\n",
      "--------------------------------------------------\n",
      "Epoch [3/10], Batch [100/200], Loss: 5.1205\n",
      "Epoch [3/10], Batch [200/200], Loss: 5.0791\n",
      "Epoch [3/10] - Train Loss: 5.0791, Val Loss: 5.5748\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "# Training configuration\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 10\n",
    "#patience = 10  # For early stopping\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding tokens\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "\n",
    "# Training history\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "print(f\"Starting training for {num_epochs} epochs...\")\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "#print(f\"Patience: {patience}\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    num_train_steps = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        src = batch['src'].to(device)\n",
    "        tgt = batch['tgt'].to(device)\n",
    "\n",
    "        # Prepare input and target for training\n",
    "        tgt_input = tgt[:, :-1]  # Remove last token (<EOS>)\n",
    "        tgt_output = tgt[:, 1:]  # Remove first token (<SOS>)\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(src, tgt_input)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(output.reshape(-1, output.shape[-1]), tgt_output.reshape(-1))\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        num_train_steps += 1\n",
    "\n",
    "        # Print progress\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            avg_loss = total_train_loss / num_train_steps\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Calculate average training loss\n",
    "    avg_train_loss = total_train_loss / num_train_steps\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    num_val_steps = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            src = batch['src'].to(device)\n",
    "            tgt = batch['tgt'].to(device)\n",
    "\n",
    "            tgt_input = tgt[:, :-1]\n",
    "            tgt_output = tgt[:, 1:]\n",
    "\n",
    "            output = model(src, tgt_input)\n",
    "            loss = criterion(output.reshape(-1, output.shape[-1]), tgt_output.reshape(-1))\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "            num_val_steps += 1\n",
    "\n",
    "    avg_val_loss = total_val_loss / num_val_steps if num_val_steps > 0 else float('inf')\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    \"\"\"\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        # Save best model\n",
    "        torch.save(model.state_dict(), 'best_transformer_model.pth')\n",
    "        print(f\"New best validation loss: {best_val_loss:.4f} - Model saved!\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# Load best model\n",
    "#model.load_state_dict(torch.load('best_transformer_model.pth'))\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Yod-89PdPmm"
   },
   "source": [
    "## Evaluation and Metrics\n",
    "\n",
    "How well did our transformer learn to translate?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "iLIv5c4wdPmn",
    "outputId": "27bfd808-6958-4bb1-846b-413e75668eed"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training loss: 2.8521\n",
      "Final validation loss: 5.2372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.2941 (29.41%)\n"
     ]
    }
   ],
   "source": [
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot on the first subplot\n",
    "plt.plot(train_losses, 'b-', label='Training Loss')\n",
    "plt.plot(val_losses, 'r-', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final training loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Final validation loss: {val_losses[-1]:.4f}\")\n",
    "\n",
    "# Calculate accuracy on validation set\n",
    "def calculate_accuracy(model, data_loader, vocab):\n",
    "    model.eval()\n",
    "    correct_tokens = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            src = batch['src'].to(device)\n",
    "            tgt = batch['tgt'].to(device)\n",
    "\n",
    "            tgt_input = tgt[:, :-1]\n",
    "            tgt_output = tgt[:, 1:]\n",
    "\n",
    "            output = model(src, tgt_input)\n",
    "            predictions = output.argmax(dim=-1)\n",
    "\n",
    "            # Only count non-padding tokens\n",
    "            mask = (tgt_output != 0)\n",
    "            correct_tokens += ((predictions == tgt_output) & mask).sum().item()\n",
    "            total_tokens += mask.sum().item()\n",
    "\n",
    "    return correct_tokens / total_tokens if total_tokens > 0 else 0\n",
    "\n",
    "val_accuracy = calculate_accuracy(model, val_loader, french_vocab)\n",
    "print(f\"Validation accuracy: {val_accuracy:.4f} ({val_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Story in Numbers**:\n",
    "- Training loss: 6.22 ‚Üí 2.85 (excellent - the model is learning!)\n",
    "- Validation loss: 5.91 ‚Üí 5.24 (concerning - barely improved)\n",
    "\n",
    "**What this tells us**: Classic overfitting! The model memorized the training data but didn't generalize. This is mathematically inevitable with only 1000 examples - production systems need millions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-uajsiUdPmn"
   },
   "source": [
    "## Inference and Translation\n",
    "\n",
    "The real test: can our transformer translate sentences it has never seen? This is where we implement autoregressive generation - the same process ChatGPT uses to generate text.\n",
    "\n",
    "### Autoregressive Generation: One Token at a Time\n",
    "\n",
    "Unlike training (where we see the entire target sequence), inference generates token-by-token:\n",
    "\n",
    "```\n",
    "Input: \"Hello world\"\n",
    "Step 1: <sos> ‚Üí \"bonjour\" (probability distribution over 1790 French words)\n",
    "Step 2: <sos> bonjour ‚Üí \"le\" \n",
    "Step 3: <sos> bonjour le ‚Üí \"monde\"\n",
    "Step 4: <sos> bonjour le monde ‚Üí <eos> (stop)\n",
    "Output: \"bonjour le monde\"\n",
    "```\n",
    "\n",
    "**Mathematical process**: At each step, the model computes P(next_word | input, previous_words) and selects the highest probability token (greedy decoding).\n",
    "\n",
    "\n",
    "Our `translate_sentence()` function implements this exactly:\n",
    "1. **Encode**: Convert English to token indices\n",
    "2. **Initialize**: Start with `<sos>` token  \n",
    "3. **Generate**: Predict next token given current sequence\n",
    "4. **Repeat**: Until `<eos>` or max length reached\n",
    "5. **Decode**: Convert token indices back to French text\n",
    "\n",
    "### Expected Results vs Reality\n",
    "\n",
    "**What good translations look like**:\n",
    "- \"Hello\" ‚Üí \"Bonjour\" (direct mapping)\n",
    "- \"Thank you\" ‚Üí \"Merci\" (common phrase)\n",
    "- \"Good morning\" ‚Üí \"Bonjour\" (contextual understanding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wpbNDTyJdPmn",
    "outputId": "e17cbd6e-715e-43b2-cb4b-0bf0d9c4124a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "English: 'Arabic is read from right to left.'\n",
      "Expected: 'L'arabe se lit de droite √† gauche.'\n",
      "Generated: 'il est √† ma ?'\n",
      "------------------------------\n",
      "Example 2:\n",
      "English: 'Compared with yours, my car is small.'\n",
      "Expected: 'Compar√©e √† ta voiture, la mienne est petite.'\n",
      "Generated: 'c'est une est un bon en train de mon soleil.'\n",
      "------------------------------\n",
      "Example 3:\n",
      "English: 'That'll be enough.'\n",
      "Expected: '√áa sera suffisant.'\n",
      "Generated: 'nous devons √† tom ?'\n",
      "------------------------------\n",
      "Example 4:\n",
      "English: 'Tom likes to climb the trees.'\n",
      "Expected: 'Tom aime grimper aux arbres.'\n",
      "Generated: 'tom a √©t√© en train de tom ?'\n",
      "------------------------------\n",
      "Example 5:\n",
      "English: 'I just took a shower.'\n",
      "Expected: 'Je viens de prendre une douche.'\n",
      "Generated: 'je n'ai pas √† une telle d'un'\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "def translate_sentence(model, sentence, src_vocab, tgt_vocab, max_length=50):\n",
    "    \"\"\"\n",
    "    Translate a single sentence using the trained model\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Convert input sentence to indices\n",
    "    src_indices = src_vocab.sentence_to_indices(sentence, add_eos=True)\n",
    "    src_tensor = torch.tensor([src_indices], dtype=torch.long).to(device)\n",
    "\n",
    "    # Initialize target with SOS token\n",
    "    tgt_indices = [tgt_vocab.word2idx[\"<sos>\"]]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            tgt_tensor = torch.tensor([tgt_indices], dtype=torch.long).to(device)\n",
    "\n",
    "            # Get model prediction\n",
    "            output = model(src_tensor, tgt_tensor)\n",
    "\n",
    "            # Get the prediction for the last token\n",
    "            next_token_logits = output[0, -1, :]\n",
    "            next_token = next_token_logits.argmax().item()\n",
    "\n",
    "            # Add predicted token to target sequence\n",
    "            tgt_indices.append(next_token)\n",
    "\n",
    "            # Stop if we predict EOS token\n",
    "            if next_token == tgt_vocab.word2idx[\"<eos>\"]:\n",
    "                break\n",
    "\n",
    "    # Convert indices back to sentence\n",
    "    translated_sentence = tgt_vocab.indices_to_sentence(tgt_indices)\n",
    "    return translated_sentence\n",
    "\n",
    "# Test on validation examples\n",
    "for i, (en_sentence, de_sentence) in enumerate(val_pairs[:5]):\n",
    "    translation = translate_sentence(model, en_sentence, english_vocab, french_vocab)\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"English: '{en_sentence}'\")\n",
    "    print(f\"Expected: '{de_sentence}'\")\n",
    "    print(f\"Generated: '{translation}'\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5yOzZm0dPmo"
   },
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've built a complete transformer translation pipeline from scratch. More importantly, you've learned why transformers work - and why they sometimes don't."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
